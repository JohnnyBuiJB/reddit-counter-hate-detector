{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import yuetal_data_preprocess\n",
    "\n",
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "def tokenize(batch):\n",
    "    # return tokenizer(batch[\"text\"], padding=True, truncation=True, add_special_tokens = True)\n",
    "    return tokenizer.encode_plus(text=batch[\"target\"],\n",
    "                       text_pair=batch[\"context\"],\n",
    "                       add_special_tokens=True, \n",
    "                       return_tensors='pt', \n",
    "                       truncation=True, \n",
    "                       max_length=512, \n",
    "                       padding='max_length', \n",
    "                       return_attention_mask=True)\n",
    "\n",
    "YU_DATA_PATH = '../reference/counter_context/data'\n",
    "\n",
    "train_df = yuetal_data_preprocess(YU_DATA_PATH + '/gold/train.jsonl', \n",
    "                                        YU_DATA_PATH + '/silver/train.jsonl')\n",
    "val_df = yuetal_data_preprocess(YU_DATA_PATH + '/gold/val.jsonl', \n",
    "                                YU_DATA_PATH + '/silver/val.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.iloc[2][\"target\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "y_train_counter = collections.Counter(train_df[\"label\"])\n",
    "print(\"y_train_counter = \", y_train_counter)\n",
    "\n",
    "y_val_counter = collections.Counter(val_df[\"label\"])\n",
    "print(\"y_val_counter = \", y_val_counter)\n",
    "\n",
    "y_val_counter[0] / (y_val_counter[0] + y_val_counter[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up-sample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_train_df = train_df[train_df.label==0]\n",
    "minority_train_df = train_df[train_df.label==1]\n",
    "\n",
    "# Upsample minority class\n",
    "upsampled_minority_train_df = resample(minority_train_df, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(majority_train_df),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "balanced_train_df = pd.concat([majority_train_df, upsampled_minority_train_df])\n",
    " \n",
    "balanced_train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, add_special_tokens = True)\n",
    "\n",
    "train_encoded = train_ds.map(tokenize, batched=True, batch_size=None)\n",
    "val_encoded = train_ds.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def roberta_encode(df, tokenizer, max_seq_length=512):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in df[['text']].values:\n",
    "        # sent = sent[0] + ' [SEP] ' +  sent[1]\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "\t\t\tsent,                      # Sentence to encode.\n",
    "\t\t\tadd_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "\t\t\tmax_length = max_seq_length,           # Pad & truncate all sentences.\n",
    "\t\t\tpad_to_max_length = True,\n",
    "\t\t\treturn_attention_mask = True,   # Construct attn. masks.\n",
    "\t\t\treturn_tensors = 'pt',     # Return pytorch tensors.\n",
    "\t\t)\n",
    "        \n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        \n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    inputs = {\n",
    "    'input_word_ids': input_ids,\n",
    "    'input_mask': attention_masks}\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def binarize_label(label):\n",
    "    if int(label) == 1:      #\"Neutral\" label combines with hate to form \"not counter-hate\"\n",
    "        label = 0\n",
    "\n",
    "    return int(label)\n",
    "\n",
    "train = roberta_encode(train_df, tokenizer)\n",
    "# train_df\n",
    "# train_labels = train_df['label'].apply(binarize_label)\n",
    "\n",
    "# val = roberta_encode(val_df, tokenizer)\n",
    "# val_labels = val_df['label'].apply(binarize_label)\n",
    "\n",
    "# test = roberta_encode(test_df, tokenizer)\n",
    "# test_labels = test_df['label'].apply(binarize_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# train_df['text'] = texts\n",
    "# print(train_df['text'][20].values)\n",
    "print(texts[20])\n",
    "train_df.iloc[20].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "# ds = DatasetDict()\n",
    "# ds['train'] = load_dataset('json', data_files=data_path + '/gold/train.jsonl')\n",
    "# ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds['train'] = ds['train'].rename_column('idx', 'input_ids')\n",
    "# ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict()\n",
    "for i in range(len(train[\"input_word_ids\"])):\n",
    "    train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tokenize(ds[\"train\"][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "compute_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_ckpt = \"roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(train_encoded) // batch_size\n",
    "print(logging_steps)\n",
    "model_name = f\"{model_ckpt}-finetuned-counter-hate\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=False, \n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=train_encoded,\n",
    "                  eval_dataset=val_encoded,\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_hidden = torch.load(\"train_hidden.pt\")\n",
    "val_hidden = torch.load(\"val_hidden.pt\")\n",
    "# y_pred = torch.load(\"y_preds.pt\")\n",
    "\n",
    "print(train_hidden)\n",
    "train_hidden['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hidden['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "y_train_counter = collections.Counter(train_hidden[\"label\"].numpy())\n",
    "print(\"y_train_counter = \", y_train_counter)\n",
    "\n",
    "y_val_counter = collections.Counter(val_hidden[\"label\"].numpy())\n",
    "print(\"y_val_counter = \", y_val_counter)\n",
    "\n",
    "# y_pred_counter = collections.Counter(y_pred)\n",
    "# print(\"y_pred_counter = \", y_pred_counter)\n",
    "y_val_counter[0] / (y_val_counter[0] + y_val_counter[1])\n",
    "# y_train_counter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(train_hidden['input_ids'][1]))\n",
    "print(train_hidden['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Listen to this wisdom. [SEP] Where the Fuck did you get that up arrow?\"\n",
    "text2 = \"Listen to this wisdom. </s> Where the Fuck did you get that up arrow?\"\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer(text1).input_ids))\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer(text2).input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2ids = list(zip(tokenizer.all_special_tokens, tokenizer.all_special_ids))\n",
    "data = sorted(tokens2ids, key=lambda x : x[-1])\n",
    "df = pd.DataFrame(data, columns=[\"Special Token\", \"Special Token ID\"])\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(train_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_y_pred = [0 if x == 1 else 2 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, title):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=True)\n",
    "    plt.title(title)\n",
    "    plt.savefig(title)\n",
    "\n",
    "\n",
    "train_hidden.features[\"label\"]\n",
    "\n",
    "y_valid = np.array(val_hidden[\"label\"])\n",
    "plot_confusion_matrix(binary_y_pred, y_valid, \"confusion_matrix\")\n",
    "\n",
    "print(accuracy_score(y_valid, binary_y_pred, normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
